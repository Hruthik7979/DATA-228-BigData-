{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5256c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/17 17:42:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/05/17 17:42:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName('DATA228_Project_1').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243624ef",
   "metadata": {},
   "source": [
    "## Importing all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb0b1346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover, CountVectorizer,Tokenizer, StringIndexer, HashingTF, IDF\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import NaiveBayes,LogisticRegression \n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator \n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323d983b",
   "metadata": {},
   "source": [
    "## Loading data into pyspark data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffabc122",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = spark.read.format('csv')\\\n",
    "          .option('header','true')\\\n",
    "          .option('inferSchema', 'true')\\\n",
    "          .option('timestamp', 'true')\\\n",
    "          .load('SF_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a688ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2129525"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4156cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.select(str.strip('PdId'),'Incident Code','Category','Descript','DayOfWeek','Date','Time','PdDistrict','X','Y')\n",
    "#display(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66f2225",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73ee0825",
   "metadata": {},
   "outputs": [],
   "source": [
    "df22=df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf2aad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df22.filter(col('Category')!=col('Descript'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d81979a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft=df2.withColumn('Date', to_date(col('Date'), \"M/d/y\"))\\\n",
    ".withColumn('Month', month(col('Date'))).withColumn('Year', year(col('Date')))\n",
    "\n",
    "dfh = dft.withColumn('Hour', hour(dft.Time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d89c271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1=dfh.filter(\"PdDistrict !='NA'\").select(col('Category'),col('Descript'))\n",
    "\n",
    "df_data=d1.withColumn('Category_1',lower(col('Category'))).withColumn('Description',lower(col('Descript'))).drop('Category','Descript').withColumnRenamed('Category_1', 'Category')\n",
    "\n",
    "df_data=df_data.select(str.strip('Description'),str.strip('Category'))\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf3673de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|         Description|      Category|\n",
      "+--------------------+--------------+\n",
      "|robbery, bodily f...|       robbery|\n",
      "|   stolen automobile| vehicle theft|\n",
      "|   stolen automobile| vehicle theft|\n",
      "|             battery|       assault|\n",
      "|             battery|       assault|\n",
      "|             battery|       assault|\n",
      "|stolen and recove...| vehicle theft|\n",
      "|             battery|       assault|\n",
      "|         trespassing|      trespass|\n",
      "|burglary of resid...|      burglary|\n",
      "|grand theft from ...| larceny/theft|\n",
      "|enroute to depart...|      warrants|\n",
      "|drivers license, ...|other offenses|\n",
      "|drivers license, ...|other offenses|\n",
      "|         trespassing|      trespass|\n",
      "|petty theft shopl...| larceny/theft|\n",
      "|robbery of a comm...|       robbery|\n",
      "|possession of heroin| drug/narcotic|\n",
      "|grand theft of pr...| larceny/theft|\n",
      "|suspicious occurr...|suspicious occ|\n",
      "+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6391465",
   "metadata": {},
   "source": [
    "## String Indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5175cd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_str_indx = StringIndexer(inputCol=\"Category\", outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faf56c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+-----+\n",
      "|         Description|     Category|label|\n",
      "+--------------------+-------------+-----+\n",
      "|petty theft from ...|larceny/theft|  0.0|\n",
      "|grand theft from ...|larceny/theft|  0.0|\n",
      "|grand theft from ...|larceny/theft|  0.0|\n",
      "|grand theft pickp...|larceny/theft|  0.0|\n",
      "|grand theft from ...|larceny/theft|  0.0|\n",
      "|petty theft from ...|larceny/theft|  0.0|\n",
      "|grand theft from ...|larceny/theft|  0.0|\n",
      "|petty theft from ...|larceny/theft|  0.0|\n",
      "|grand theft from ...|larceny/theft|  0.0|\n",
      "|grand theft from ...|larceny/theft|  0.0|\n",
      "|petty theft from ...|larceny/theft|  0.0|\n",
      "|grand theft from ...|larceny/theft|  0.0|\n",
      "|grand theft from ...|larceny/theft|  0.0|\n",
      "|grand theft from ...|larceny/theft|  0.0|\n",
      "|grand theft from ...|larceny/theft|  0.0|\n",
      "|grand theft from ...|larceny/theft|  0.0|\n",
      "|lost property, gr...|larceny/theft|  0.0|\n",
      "|petty theft from ...|larceny/theft|  0.0|\n",
      "|grand theft from ...|larceny/theft|  0.0|\n",
      "|grand theft from ...|larceny/theft|  0.0|\n",
      "+--------------------+-------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_ind=data_str_indx.fit(df_data).transform(df_data).sort('label')\n",
    "(data_ind.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92170572",
   "metadata": {},
   "source": [
    "## Label Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02baef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict=data_ind.select(col('label'),col('Category')).distinct().sort('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb69fa86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 7:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------------+\n",
      "|label|Category              |\n",
      "+-----+----------------------+\n",
      "|0.0  |larceny/theft         |\n",
      "|1.0  |other offenses        |\n",
      "|2.0  |non-criminal          |\n",
      "|3.0  |assault               |\n",
      "|4.0  |vehicle theft         |\n",
      "|5.0  |drug/narcotic         |\n",
      "|6.0  |vandalism             |\n",
      "|7.0  |warrants              |\n",
      "|8.0  |burglary              |\n",
      "|9.0  |suspicious occ        |\n",
      "|10.0 |robbery               |\n",
      "|11.0 |missing person        |\n",
      "|12.0 |fraud                 |\n",
      "|13.0 |forgery/counterfeiting|\n",
      "|14.0 |secondary codes       |\n",
      "|15.0 |weapon laws           |\n",
      "|16.0 |trespass              |\n",
      "|17.0 |prostitution          |\n",
      "|18.0 |stolen property       |\n",
      "|19.0 |disorderly conduct    |\n",
      "+-----+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "label_dict.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d3e54e",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e49bc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(outputCol=\"words\",inputCol=(\"Description\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac385e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 10:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+-----+--------------------+\n",
      "|         Description|     Category|label|               words|\n",
      "+--------------------+-------------+-----+--------------------+\n",
      "|petty theft from ...|larceny/theft|  0.0|[petty, theft, fr...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...|\n",
      "|grand theft pickp...|larceny/theft|  0.0|[grand, theft, pi...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...|\n",
      "|petty theft from ...|larceny/theft|  0.0|[petty, theft, fr...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...|\n",
      "|petty theft from ...|larceny/theft|  0.0|[petty, theft, fr...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...|\n",
      "|petty theft from ...|larceny/theft|  0.0|[petty, theft, fr...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...|\n",
      "|lost property, gr...|larceny/theft|  0.0|[lost, property,,...|\n",
      "|petty theft from ...|larceny/theft|  0.0|[petty, theft, fr...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...|\n",
      "+--------------------+-------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 10:==================================================>       (7 + 1) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_tok=tokenizer.transform(data_ind)\n",
    "(data_tok.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7721806a",
   "metadata": {},
   "source": [
    "## Stop words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45597c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "remover = StopWordsRemover().setInputCol(\"words\").setOutputCol(\"words_after_stopwords\")\n",
    "#stopwords = remover.getStopWords()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86697e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+-----+--------------------+---------------------+\n",
      "|         Description|     Category|label|               words|words_after_stopwords|\n",
      "+--------------------+-------------+-----+--------------------+---------------------+\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...| [grand, theft, lo...|\n",
      "|petty theft shopl...|larceny/theft|  0.0|[petty, theft, sh...| [petty, theft, sh...|\n",
      "|grand theft of pr...|larceny/theft|  0.0|[grand, theft, of...| [grand, theft, pr...|\n",
      "|grand theft pickp...|larceny/theft|  0.0|[grand, theft, pi...| [grand, theft, pi...|\n",
      "|petty theft of pr...|larceny/theft|  0.0|[petty, theft, of...| [petty, theft, pr...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...| [grand, theft, pe...|\n",
      "|petty theft from ...|larceny/theft|  0.0|[petty, theft, fr...| [petty, theft, bu...|\n",
      "|petty theft of pr...|larceny/theft|  0.0|[petty, theft, of...| [petty, theft, pr...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...| [grand, theft, lo...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...| [grand, theft, un...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...| [grand, theft, lo...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...| [grand, theft, lo...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...| [grand, theft, lo...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...| [grand, theft, lo...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...| [grand, theft, lo...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...| [grand, theft, bu...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...| [grand, theft, pe...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...| [grand, theft, bu...|\n",
      "|grand theft of pr...|larceny/theft|  0.0|[grand, theft, of...| [grand, theft, pr...|\n",
      "|grand theft of pr...|larceny/theft|  0.0|[grand, theft, of...| [grand, theft, pr...|\n",
      "+--------------------+-------------+-----+--------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_rem=remover.transform(data_tok)\n",
    "(data_rem.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d583d16b",
   "metadata": {},
   "source": [
    "### Count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87dd5523",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(minDF=2).setInputCol(\"words_after_stopwords\").setOutputCol(\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "342e1ad6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+-----+--------------------+---------------------+--------------------+\n",
      "|         Description|     Category|label|               words|words_after_stopwords|            features|\n",
      "+--------------------+-------------+-----+--------------------+---------------------+--------------------+\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...| [grand, theft, lo...|(997,[0,1,2,3],[1...|\n",
      "|petty theft shopl...|larceny/theft|  0.0|[petty, theft, sh...| [petty, theft, sh...|(997,[0,5,51],[1....|\n",
      "|grand theft of pr...|larceny/theft|  0.0|[grand, theft, of...| [grand, theft, pr...|(997,[0,1,4],[1.0...|\n",
      "|grand theft pickp...|larceny/theft|  0.0|[grand, theft, pi...| [grand, theft, pi...|(997,[0,1,97],[1....|\n",
      "|petty theft of pr...|larceny/theft|  0.0|[petty, theft, of...| [petty, theft, pr...|(997,[0,4,5],[1.0...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...| [grand, theft, pe...|(997,[0,1,31],[1....|\n",
      "|petty theft from ...|larceny/theft|  0.0|[petty, theft, fr...| [petty, theft, bu...|(997,[0,5,32],[1....|\n",
      "|petty theft of pr...|larceny/theft|  0.0|[petty, theft, of...| [petty, theft, pr...|(997,[0,4,5],[1.0...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...| [grand, theft, lo...|(997,[0,1,2,3],[1...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...| [grand, theft, un...|(997,[0,1,2,65],[...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...| [grand, theft, lo...|(997,[0,1,2,3],[1...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...| [grand, theft, lo...|(997,[0,1,2,3],[1...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...| [grand, theft, lo...|(997,[0,1,2,3],[1...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...| [grand, theft, lo...|(997,[0,1,2,3],[1...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...| [grand, theft, lo...|(997,[0,1,2,3],[1...|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...| [grand, theft, bu...|(997,[0,1,32],[1....|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...| [grand, theft, pe...|(997,[0,1,31],[1....|\n",
      "|grand theft from ...|larceny/theft|  0.0|[grand, theft, fr...| [grand, theft, bu...|(997,[0,1,32],[1....|\n",
      "|grand theft of pr...|larceny/theft|  0.0|[grand, theft, of...| [grand, theft, pr...|(997,[0,1,4],[1.0...|\n",
      "|grand theft of pr...|larceny/theft|  0.0|[grand, theft, of...| [grand, theft, pr...|(997,[0,1,4],[1.0...|\n",
      "+--------------------+-------------+-----+--------------------+---------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 24:===========================================>              (6 + 2) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = cv.fit(data_rem)\n",
    "\n",
    "data_cv=model.transform(data_rem)\n",
    "(data_cv.show())## sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591451ac",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82274065",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashed_df=HashingTF(inputCol=\"words_after_stopwords\", outputCol=\"hash_features\",numFeatures=9000)\n",
    "idf = IDF(inputCol=\"hash_features\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a49268c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_data=hashed_df.transform(data_rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86360de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "idf_data = idf.fit(hash_data).transform(hash_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b4f9cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 51:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(9000,[2434,2785,...|\n",
      "|  0.0|(9000,[590,2434,2...|\n",
      "|  0.0|(9000,[590,5182,6...|\n",
      "|  0.0|(9000,[590,5182,5...|\n",
      "|  0.0|(9000,[590,2434,2...|\n",
      "|  0.0|(9000,[2434,2785,...|\n",
      "|  0.0|(9000,[590,2434,2...|\n",
      "|  0.0|(9000,[2434,2785,...|\n",
      "|  0.0|(9000,[590,2434,2...|\n",
      "|  0.0|(9000,[590,2434,2...|\n",
      "|  0.0|(9000,[2434,2785,...|\n",
      "|  0.0|(9000,[590,5182,6...|\n",
      "|  0.0|(9000,[590,2434,2...|\n",
      "|  0.0|(9000,[590,2434,2...|\n",
      "|  0.0|(9000,[590,2434,2...|\n",
      "|  0.0|(9000,[590,2434,2...|\n",
      "|  0.0|(9000,[590,1233,3...|\n",
      "|  0.0|(9000,[2434,2785,...|\n",
      "|  0.0|(9000,[590,2434,2...|\n",
      "|  0.0|(9000,[590,2434,2...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(idf_data.select(\"label\", \"features\").show()) ## sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d5ead7",
   "metadata": {},
   "source": [
    "### Train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06f4857f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = data_ind.randomSplit([0.7,0.3], seed=60)\n",
    "#training, test_i = idf_data.randomSplit([0.7,0.3], seed=60)\n",
    "#training_cv, test_cv = data_cv.randomSplit([0.7,0.3], seed=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b33626f",
   "metadata": {},
   "source": [
    "## Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5527c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(family=\"multinomial\",maxIter=20, regParam=0.4, elasticNetParam=0)\n",
    "#rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754fed9f",
   "metadata": {},
   "source": [
    "### Pipeline for logistic regression with count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61dd71dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/17 17:43:43 WARN InstanceBuilder$JavaBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 48:>                                                         (0 + 7) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/17 17:43:44 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/05/17 17:43:44 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/17 17:43:46 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "23/05/17 17:43:46 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 111:>                                                        (0 + 8) / 8]\r"
     ]
    }
   ],
   "source": [
    "pipe_cv_lr = Pipeline(stages=[tokenizer,remover,cv, lr])\n",
    "model_cv_lr = pipe_cv_lr.fit(training)\n",
    "pred_cv_lr = model_cv_lr.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fd2405",
   "metadata": {},
   "source": [
    "### Pipeline for logistic regression with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e91611bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 188:>                                                        (0 + 8) / 8]\r"
     ]
    }
   ],
   "source": [
    "pipe_idf_lr = Pipeline(stages=[tokenizer,remover,hashed_df,idf, lr])\n",
    "model_idf_lr = pipe_idf_lr.fit(training)\n",
    "pred_idf_lr = model_idf_lr.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8453f9ea",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93db1ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(pred_cv_lr)\n",
    "\n",
    "\n",
    "# Other metrics\n",
    "precision = evaluator.evaluate(pred_cv_lr, {evaluator.metricName: \"weightedPrecision\"})\n",
    "recall = evaluator.evaluate(pred_cv_lr, {evaluator.metricName: \"weightedRecall\"})\n",
    "f1_score = evaluator.evaluate(pred_cv_lr, {evaluator.metricName: \"f1\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e71490",
   "metadata": {},
   "source": [
    "### Evaluation metrices for logistic regression with count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c0bd430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.958\n",
      "Precision: 0.9562 \n",
      "Recall: 0.958\n",
      "F1: 0.9463\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {:.4}\".format(accuracy))\n",
    "print(\"Precision: {:.4} \".format(precision))\n",
    "print(\"Recall: {:.4}\".format(recall))\n",
    "print(\"F1: {:.4}\".format(f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1575f68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy_lr_idf = evaluator.evaluate(pred_idf_lr)\n",
    "\n",
    "\n",
    "# Other metrics\n",
    "precision_lr_idf = evaluator.evaluate(pred_idf_lr, {evaluator.metricName: \"weightedPrecision\"})\n",
    "recall_lr_idf = evaluator.evaluate(pred_idf_lr, {evaluator.metricName: \"weightedRecall\"})\n",
    "f1_score_lr_idf = evaluator.evaluate(pred_idf_lr, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6426ca4b",
   "metadata": {},
   "source": [
    "### Evaluation metrices for logistic regression with TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f12ff8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9575\n",
      "Precision: 0.9557 \n",
      "Recall: 0.9575\n",
      "F1: 0.9457\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {:.4}\".format(accuracy_lr_idf))\n",
    "print(\"Precision: {:.4} \".format(precision_lr_idf))\n",
    "print(\"Recall: {:.4}\".format(recall_lr_idf))\n",
    "print(\"F1: {:.4}\".format(f1_score_lr_idf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516d63d6",
   "metadata": {},
   "source": [
    "## Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1471710",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes(smoothing=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349cb872",
   "metadata": {},
   "source": [
    "### Pipeline for Naive Bayes model with count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1e7736fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pipe_cv_nv = Pipeline(stages=[tokenizer,remover,cv, nb])\n",
    "model_cv_nv = pipe_cv_nv.fit(training)\n",
    "pred_cv_nv = model_cv_nv.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52abc328",
   "metadata": {},
   "source": [
    "### Pipeline for Naive Bayes model with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "748ad267",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pipe_idf_nb = Pipeline(stages=[tokenizer,remover,hashed_df,idf, nb])\n",
    "model_idf_nb = pipe_idf_nb.fit(training)\n",
    "pred_idf_nb = model_idf_nb.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdbf559",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ddae3ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "evaluator_nb = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy_nb = evaluator_nb.evaluate(pred_cv_nv)\n",
    "\n",
    "\n",
    "# Other metrics\n",
    "precision_nb = evaluator_nb.evaluate(pred_cv_nv, {evaluator_nb.metricName: \"weightedPrecision\"})\n",
    "recall_nb = evaluator_nb.evaluate(pred_cv_nv, {evaluator_nb.metricName: \"weightedRecall\"})\n",
    "f1_score_nb = evaluator_nb.evaluate(pred_cv_nv, {evaluator_nb.metricName: \"f1\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4efbbd0",
   "metadata": {},
   "source": [
    "### Evaluation metrices for Naive Bayes model with count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50959816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9946\n",
      "Precision: 0.9958 \n",
      "Recall: 0.9946\n",
      "F1: 0.995\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {:.4}\".format(accuracy_nb))\n",
    "print(\"Precision: {:.4} \".format(precision_nb))\n",
    "print(\"Recall: {:.4}\".format(recall_nb))\n",
    "print(\"F1: {:.4}\".format(f1_score_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e5cc930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 292:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/17 17:51:50 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 297:=================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/17 17:51:54 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 302:===================================>                     (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/17 17:51:57 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "accuracy_nb_idf = evaluator.evaluate(pred_cv_nv)\n",
    "\n",
    "\n",
    "# Other metrics\n",
    "precision_nb_idf = evaluator_nb.evaluate(pred_idf_nb, {evaluator_nb.metricName: \"weightedPrecision\"})\n",
    "recall_nb_idf = evaluator_nb.evaluate(pred_idf_nb, {evaluator_nb.metricName: \"weightedRecall\"})\n",
    "f1_score_nb_idf = evaluator_nb.evaluate(pred_idf_nb, {evaluator_nb.metricName: \"f1\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f241ecd",
   "metadata": {},
   "source": [
    "### Evaluation metrices for Naive Bayes with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58630615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9946\n",
      "Precision: 0.9955 \n",
      "Recall: 0.993\n",
      "F1: 0.9939\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {:.4}\".format(accuracy_nb_idf))\n",
    "print(\"Precision: {:.4} \".format(precision_nb_idf))\n",
    "print(\"Recall: {:.4}\".format(recall_nb_idf))\n",
    "print(\"F1: {:.4}\".format(f1_score_nb_idf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8eaca1e",
   "metadata": {},
   "source": [
    "## How does model classify  new data sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b3644375",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = spark.createDataFrame([(\"stolen vehicle from downtown\",StringType())\n",
    "],\n",
    "[\"Description\"]\n",
    "\n",
    ")\n",
    "pred_sample_cv_lr = model_cv_lr.transform(sample_data)\n",
    "pred_sample_idf_lr = model_idf_lr.transform(sample_data) ##  was selling drugs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "51ea7d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+\n",
      "|         Description|         probability|prediction|\n",
      "+--------------------+--------------------+----------+\n",
      "|stolen vehicle fr...|[0.13098373506775...|       4.0|\n",
      "+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_sample_cv_lr.select('Description',\"probability\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "250e138b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+\n",
      "|         Description|         probability|prediction|\n",
      "+--------------------+--------------------+----------+\n",
      "|stolen vehicle fr...|[0.10889471793392...|       4.0|\n",
      "+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_sample_idf_lr.select('Description',\"probability\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6d7c9b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 327:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------+\n",
      "|label|Category                   |\n",
      "+-----+---------------------------+\n",
      "|0.0  |larceny/theft              |\n",
      "|1.0  |other offenses             |\n",
      "|2.0  |non-criminal               |\n",
      "|3.0  |assault                    |\n",
      "|4.0  |vehicle theft              |\n",
      "|5.0  |drug/narcotic              |\n",
      "|6.0  |vandalism                  |\n",
      "|7.0  |warrants                   |\n",
      "|8.0  |burglary                   |\n",
      "|9.0  |suspicious occ             |\n",
      "|10.0 |robbery                    |\n",
      "|11.0 |missing person             |\n",
      "|12.0 |fraud                      |\n",
      "|13.0 |forgery/counterfeiting     |\n",
      "|14.0 |secondary codes            |\n",
      "|15.0 |weapon laws                |\n",
      "|16.0 |trespass                   |\n",
      "|17.0 |prostitution               |\n",
      "|18.0 |stolen property            |\n",
      "|19.0 |disorderly conduct         |\n",
      "|20.0 |drunkenness                |\n",
      "|21.0 |sex offenses, forcible     |\n",
      "|22.0 |recovered vehicle          |\n",
      "|23.0 |driving under the influence|\n",
      "|24.0 |kidnapping                 |\n",
      "|25.0 |embezzlement               |\n",
      "|26.0 |liquor laws                |\n",
      "|27.0 |arson                      |\n",
      "|28.0 |loitering                  |\n",
      "|29.0 |suicide                    |\n",
      "|30.0 |bad checks                 |\n",
      "|31.0 |bribery                    |\n",
      "|32.0 |extortion                  |\n",
      "|33.0 |gambling                   |\n",
      "|34.0 |pornography/obscene mat    |\n",
      "|35.0 |sex offenses, non forcible |\n",
      "|36.0 |trea                       |\n",
      "+-----+---------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 327:==========================================>              (6 + 2) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "label_dict.show(40,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0e9bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
